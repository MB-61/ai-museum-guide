<!DOCTYPE html>
<html lang="tr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI MÃ¼ze Rehberi - Avatar</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body,
        html {
            width: 100%;
            height: 100%;
            font-family: 'Segoe UI', Arial, sans-serif;
            background: linear-gradient(135deg, #0a0a1a 0%, #1a1a3e 50%, #0f2840 100%);
            color: white;
            overflow: hidden;
        }

        .container {
            display: flex;
            flex-direction: column;
            height: 100vh;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
        }

        #avatar {
            flex: 1;
            width: 100%;
            border-radius: 24px;
            background: radial-gradient(ellipse at center, rgba(100, 120, 200, 0.1) 0%, transparent 70%);
            border: 1px solid rgba(255, 255, 255, 0.08);
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5), inset 0 0 100px rgba(100, 120, 200, 0.05);
        }

        .controls {
            display: flex;
            gap: 12px;
            padding: 20px 0;
            align-items: center;
            flex-wrap: wrap;
        }

        select,
        input {
            padding: 14px 18px;
            border: none;
            border-radius: 12px;
            background: rgba(255, 255, 255, 0.08);
            color: white;
            font-size: 15px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            transition: all 0.3s;
        }

        select:focus,
        input:focus {
            outline: none;
            border-color: rgba(102, 126, 234, 0.5);
            box-shadow: 0 0 20px rgba(102, 126, 234, 0.2);
        }

        select option {
            background: #1a1a2e;
        }

        #text {
            flex: 1;
            min-width: 300px;
        }

        button {
            padding: 14px 32px;
            border: none;
            border-radius: 12px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 15px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 4px 20px rgba(102, 126, 234, 0.3);
        }

        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 6px 30px rgba(102, 126, 234, 0.4);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        button.speaking {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {

            0%,
            100% {
                box-shadow: 0 4px 20px rgba(245, 87, 108, 0.3);
            }

            50% {
                box-shadow: 0 4px 40px rgba(245, 87, 108, 0.6);
            }
        }

        #status {
            text-align: center;
            padding: 12px;
            font-size: 14px;
            color: rgba(255, 255, 255, 0.6);
            letter-spacing: 0.5px;
        }

        .ready {
            color: #4ade80 !important;
        }

        .loading {
            color: #667eea !important;
        }

        .speaking {
            color: #f5576c !important;
        }

        .error {
            color: #f87171 !important;
        }

        /* Subtitle display */
        #subtitle {
            position: absolute;
            bottom: 180px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.7);
            padding: 12px 24px;
            border-radius: 12px;
            font-size: 18px;
            max-width: 80%;
            text-align: center;
            backdrop-filter: blur(10px);
            opacity: 0;
            transition: opacity 0.3s;
        }

        #subtitle.visible {
            opacity: 1;
        }

        #log {
            position: fixed;
            bottom: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.85);
            padding: 12px;
            border-radius: 12px;
            font-size: 11px;
            max-width: 400px;
            max-height: 150px;
            overflow-y: auto;
            font-family: 'Consolas', monospace;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            display: none;
            /* Hidden by default */
        }

        #log.visible {
            display: block;
        }

        #debugToggle {
            position: fixed;
            bottom: 10px;
            right: 10px;
            background: rgba(255, 255, 255, 0.1);
            padding: 8px 16px;
            border-radius: 8px;
            font-size: 12px;
            cursor: pointer;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
    </style>

    <script
        src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@latest/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>

    <!-- Config dosyasÄ± (API Keys) - .gitignore'da, GitHub'a yÃ¼klenmez -->
    <script src="config.js"></script>

    <script type="importmap">
    { "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.180.0/build/three.module.js/+esm",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.180.0/examples/jsm/",
        "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.7/modules/talkinghead.mjs"
    }}
    </script>

    <script type="module">
        import { TalkingHead } from "talkinghead";

        // API anahtarlarÄ± config.js dosyasÄ±ndan alÄ±nÄ±yor
        const AZURE_KEY = CONFIG.AZURE_SPEECH_KEY;
        const AZURE_REGION = CONFIG.AZURE_SPEECH_REGION;

        let head, isReady = false, audioContext = null, morphMeshes = [];

        // Enhanced viseme mapping with intensities
        const visemeConfig = {
            0: { name: "sil", intensity: 0.0 },
            1: { name: "aa", intensity: 0.8 },
            2: { name: "aa", intensity: 0.7 },
            3: { name: "O", intensity: 0.7 },
            4: { name: "E", intensity: 0.6 },
            5: { name: "I", intensity: 0.5 },
            6: { name: "I", intensity: 0.5 },
            7: { name: "U", intensity: 0.7 },
            8: { name: "O", intensity: 0.6 },
            9: { name: "aa", intensity: 0.7 },
            10: { name: "O", intensity: 0.6 },
            11: { name: "I", intensity: 0.5 },
            12: { name: "kk", intensity: 0.4 },
            13: { name: "RR", intensity: 0.5 },
            14: { name: "nn", intensity: 0.4 },
            15: { name: "SS", intensity: 0.5 },
            16: { name: "CH", intensity: 0.6 },
            17: { name: "TH", intensity: 0.5 },
            18: { name: "FF", intensity: 0.6 },
            19: { name: "DD", intensity: 0.5 },
            20: { name: "kk", intensity: 0.4 },
            21: { name: "PP", intensity: 0.8 }
        };

        function log(msg) {
            const logDiv = document.getElementById('log');
            logDiv.innerHTML += `[${new Date().toLocaleTimeString()}] ${msg}<br>`;
            logDiv.scrollTop = logDiv.scrollHeight;
            console.log(msg);
        }

        function setStatus(msg, type) {
            const el = document.getElementById('status');
            el.textContent = msg;
            el.className = type;
        }

        function showSubtitle(text) {
            const el = document.getElementById('subtitle');
            el.textContent = text;
            el.classList.add('visible');
        }

        function hideSubtitle() {
            document.getElementById('subtitle').classList.remove('visible');
        }

        async function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            if (audioContext.state === 'suspended') await audioContext.resume();
            return audioContext;
        }

        function pcmToAudioBuffer(pcmData, sampleRate) {
            const audioBuffer = audioContext.createBuffer(1, pcmData.length, sampleRate);
            const channelData = audioBuffer.getChannelData(0);
            for (let i = 0; i < pcmData.length; i++) {
                channelData[i] = pcmData[i] / 32768.0;
            }
            return audioBuffer;
        }

        function playAudioBuffer(audioBuffer) {
            return new Promise((resolve) => {
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.onended = resolve;
                source.start();
            });
        }

        function findMorphMeshes() {
            morphMeshes = [];
            if (head?.scene) {
                head.scene.traverse(node => {
                    if (node.isMesh && node.morphTargetDictionary && node.morphTargetInfluences) {
                        const visemeKeys = Object.keys(node.morphTargetDictionary).filter(k => k.startsWith('viseme_'));
                        if (visemeKeys.length > 0) {
                            morphMeshes.push({
                                mesh: node,
                                dict: node.morphTargetDictionary,
                                influences: node.morphTargetInfluences
                            });
                        }
                    }
                });
            }
            return morphMeshes;
        }

        // Smooth viseme transition
        let currentVisemeValues = {};
        const visemeNames = ['sil', 'aa', 'E', 'I', 'O', 'U', 'PP', 'FF', 'TH', 'DD', 'kk', 'CH', 'SS', 'nn', 'RR'];
        visemeNames.forEach(v => currentVisemeValues[v] = 0);

        function setVisemeSmooth(targetViseme, targetIntensity, lerpSpeed = 0.3) {
            visemeNames.forEach(v => {
                const target = (v === targetViseme) ? targetIntensity : 0;
                currentVisemeValues[v] += (target - currentVisemeValues[v]) * lerpSpeed;

                const fullName = 'viseme_' + v;
                morphMeshes.forEach(m => {
                    const idx = m.dict[fullName];
                    if (idx !== undefined) {
                        m.influences[idx] = Math.max(0, currentVisemeValues[v]);
                    }
                });
            });
        }

        function resetVisemes() {
            visemeNames.forEach(v => currentVisemeValues[v] = 0);
            morphMeshes.forEach(m => {
                Object.keys(m.dict).forEach(key => {
                    if (key.startsWith('viseme_')) {
                        m.influences[m.dict[key]] = 0;
                    }
                });
            });
        }

        // Enhanced lip-sync with smooth interpolation
        async function animateLipSync(visemeData, totalDuration) {
            if (visemeData.length === 0) return;

            const startTime = performance.now();
            let currentIdx = 0;
            let animationId;

            return new Promise((resolve) => {
                function update() {
                    const elapsed = performance.now() - startTime;

                    // Find current viseme
                    while (currentIdx < visemeData.length - 1 && visemeData[currentIdx + 1].time <= elapsed) {
                        currentIdx++;
                    }

                    const current = visemeData[currentIdx];
                    const config = visemeConfig[current.id] || { name: "sil", intensity: 0 };

                    // Smooth transition
                    setVisemeSmooth(config.name, config.intensity, 0.35);

                    if (elapsed < totalDuration * 1000) {
                        animationId = requestAnimationFrame(update);
                    } else {
                        // Smooth fade out
                        let fadeStep = 0;
                        function fadeOut() {
                            fadeStep++;
                            setVisemeSmooth("sil", 0, 0.2);
                            if (fadeStep < 10) {
                                requestAnimationFrame(fadeOut);
                            } else {
                                resetVisemes();
                                resolve();
                            }
                        }
                        fadeOut();
                    }
                }

                animationId = requestAnimationFrame(update);
            });
        }

        async function speak(text, voiceName) {
            log('Speaking: ' + text.substring(0, 30) + '...');
            setStatus('Azure TTS\'e baÄŸlanÄ±yor...', 'loading');
            showSubtitle(text);

            const btnSpeak = document.getElementById('speak');
            btnSpeak.classList.add('speaking');

            await initAudioContext();

            const lang = voiceName.startsWith('tr-') ? 'tr-TR' : 'en-US';
            const ssml = `<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts" xml:lang="${lang}">
                <voice name="${voiceName}">
                    <mstts:viseme type="redlips_front"/>
                    ${text.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;')}
                </voice>
            </speak>`;

            const config = SpeechSDK.SpeechConfig.fromSubscription(AZURE_KEY, AZURE_REGION);
            config.speechSynthesisOutputFormat = SpeechSDK.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm;

            const synth = new SpeechSDK.SpeechSynthesizer(config, null);
            const visemeData = [];

            synth.visemeReceived = (s, e) => {
                visemeData.push({
                    id: e.visemeId,
                    time: e.audioOffset / 10000 // ms
                });
            };

            return new Promise((resolve, reject) => {
                synth.speakSsmlAsync(ssml,
                    async result => {
                        btnSpeak.classList.remove('speaking');

                        if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                            const pcmData = new Int16Array(result.audioData);
                            const audioBuffer = pcmToAudioBuffer(pcmData, 24000);
                            const duration = audioBuffer.duration;

                            log(`Audio: ${(result.audioData.byteLength / 1024).toFixed(1)}KB, ${duration.toFixed(1)}s, ${visemeData.length} visemes`);
                            setStatus('KonuÅŸuyor...', 'speaking');

                            // Play audio and animate in parallel
                            await Promise.all([
                                playAudioBuffer(audioBuffer),
                                animateLipSync(visemeData, duration)
                            ]);

                            hideSubtitle();
                            setStatus('HazÄ±r', 'ready');
                            log('Completed');
                            resolve();
                        } else {
                            hideSubtitle();
                            setStatus('Hata: ' + result.errorDetails, 'error');
                            reject(result.errorDetails);
                        }
                        synth.close();
                    },
                    error => {
                        btnSpeak.classList.remove('speaking');
                        hideSubtitle();
                        setStatus('BaÄŸlantÄ± hatasÄ±', 'error');
                        synth.close();
                        reject(error);
                    }
                );
            });
        }

        document.addEventListener('DOMContentLoaded', async () => {
            const btnSpeak = document.getElementById('speak');
            btnSpeak.disabled = true;

            setStatus('Avatar yÃ¼kleniyor...', 'loading');

            try {
                const nodeAvatar = document.getElementById('avatar');
                head = new TalkingHead(nodeAvatar, {
                    ttsEndpoint: null,
                    lipsyncModules: ["en"],
                    cameraView: "upper"
                });

                window.head = head;

                await head.showAvatar({
                    url: './avatar.glb',
                    body: 'M',
                    avatarMood: 'neutral',
                    lipsyncLang: 'en'
                }, (ev) => {
                    if (ev.lengthComputable) {
                        setStatus('Avatar: ' + Math.round(ev.loaded / ev.total * 100) + '%', 'loading');
                    }
                });

                findMorphMeshes();
                log('Avatar loaded, ' + morphMeshes.length + ' morph meshes');

                setStatus('HazÄ±r - Bir ÅŸey yazÄ±n ve KonuÅŸ butonuna tÄ±klayÄ±n', 'ready');
                btnSpeak.disabled = false;
                isReady = true;

            } catch (err) {
                log('Error: ' + err.message);
                setStatus('Hata: ' + err.message, 'error');
            }

            btnSpeak.addEventListener('click', async () => {
                if (!isReady) return;
                const text = document.getElementById('text').value.trim();
                const voice = document.getElementById('voice').value;
                if (text) {
                    btnSpeak.disabled = true;
                    try {
                        await speak(text, voice);
                    } catch (err) {
                        log('Error: ' + err);
                    }
                    btnSpeak.disabled = false;
                }
            });

            document.getElementById('text').addEventListener('keypress', (e) => {
                if (e.key === 'Enter' && !btnSpeak.disabled) btnSpeak.click();
            });

            document.getElementById('debugToggle').addEventListener('click', () => {
                document.getElementById('log').classList.toggle('visible');
            });

            document.addEventListener("visibilitychange", () => {
                if (document.visibilityState === "visible") head?.start();
                else head?.stop();
            });
        });
    </script>
</head>

<body>
    <div class="container">
        <div id="avatar"></div>
        <div id="subtitle"></div>
        <div class="controls">
            <select id="voice">
                <optgroup label="TÃ¼rkÃ§e">
                    <option value="tr-TR-AhmetNeural" selected>Ahmet (Erkek)</option>
                    <option value="tr-TR-EmelNeural">Emel (KadÄ±n)</option>
                </optgroup>
                <optgroup label="English">
                    <option value="en-US-GuyNeural">Guy (Male)</option>
                    <option value="en-US-JennyNeural">Jenny (Female)</option>
                    <option value="en-GB-RyanNeural">Ryan (British)</option>
                </optgroup>
            </select>
            <input id="text" type="text" placeholder="KonuÅŸmasÄ±nÄ± istediÄŸiniz metni yazÄ±n..."
                value="Merhaba! Ben yapay zeka mÃ¼ze rehberinizim. Size nasÄ±l yardÄ±mcÄ± olabilirim?">
            <button id="speak">ðŸŽ¤ KonuÅŸ</button>
        </div>
        <div id="status" class="loading">YÃ¼kleniyor...</div>
    </div>
    <div id="log"></div>
    <div id="debugToggle">ðŸ”§ Debug</div>
</body>

</html>